"""
å­¦æœ¯èŠå¤©æœºå™¨äºº - ä¸»åº”ç”¨
æ”¯æŒåŸºç¡€è¯¾ç¨‹ææ–™é—®ç­” + ç”¨æˆ·æ–‡æ¡£ä¸Šä¼ 
"""

import streamlit as st
import os
import json
from datetime import datetime
from document_manager import DocumentManager
from rag_system import DualVectorStoreRAG
from utils import format_file_size, get_directory_size, safe_remove_file

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å­¦æœ¯èŠå¤©æœºå™¨äºº", 
    page_icon="ğŸ“", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“‘ McMaster Academic Knowledge QA System V1.0")
st.markdown("Based on course materials default and uploaded by users and RAG.")


# ==================== é…ç½®åŠ è½½ ====================
@st.cache_resource
def load_config():
    """
    é…ç½®åŠ è½½ä¼˜å…ˆçº§ï¼š
    1. Streamlit Secretsï¼ˆæ¨èç”¨äºéƒ¨ç½²ï¼‰
    2. ç¯å¢ƒå˜é‡
    3. config.json æ–‡ä»¶ï¼ˆæœ¬åœ°å¼€å‘ï¼‰
    """
    # è·å– OpenAI API Key
    openai_key = None
    if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
        openai_key = st.secrets['OPENAI_API_KEY']
        source = "Streamlit Secrets"
    elif 'OPENAI_API_KEY' in os.environ:
        openai_key = os.environ['OPENAI_API_KEY']
        source = "Environment Variable"
    else:
        try:
            with open("config.json", "r", encoding="utf-8") as f:
                config = json.load(f)
            openai_key = config.get("OpenAIAPIKey")
            source = "config.json"
        except FileNotFoundError:
            pass
    
    if not openai_key:
        st.error("""
        âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼
        
        è¯·é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼é…ç½®ï¼š
        
        **1. Streamlit Cloud éƒ¨ç½²ï¼ˆæ¨èï¼‰ï¼š**
        - åœ¨ Streamlit Cloud è®¾ç½®ä¸­æ·»åŠ  Secrets
        - æ ¼å¼: `OPENAI_API_KEY = "your-key-here"`
        
        **2. æœ¬åœ°ç¯å¢ƒå˜é‡ï¼š**
        ```bash
        export OPENAI_API_KEY="your-key-here"
        ```
        
        **3. æœ¬åœ° config.json æ–‡ä»¶ï¼š**
        ```json
        {
          "OpenAIAPIKey": "your-key-here"
        }
        ```
        """)
        st.stop()
    
    # è®¾ç½® OpenAI API Key
    os.environ['OPENAI_API_KEY'] = openai_key
    
    # è·å– LangChain API Key (å¯é€‰)
    langchain_key = None
    if hasattr(st, 'secrets') and 'LANGCHAIN_API_KEY' in st.secrets:
        langchain_key = st.secrets['LANGCHAIN_API_KEY']
    elif 'LANGCHAIN_API_KEY' in os.environ:
        langchain_key = os.environ['LANGCHAIN_API_KEY']
    else:
        try:
            with open("config.json", "r", encoding="utf-8") as f:
                config = json.load(f)
            langchain_key = config.get("LangChainAPIKey")
        except:
            pass
    
    # é…ç½® LangSmith è¿½è¸ªï¼ˆå¦‚æœæä¾›äº† API Keyï¼‰
    if langchain_key:
        os.environ['LANGCHAIN_TRACING_V2'] = 'true'
        os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'
        os.environ['LANGCHAIN_API_KEY'] = langchain_key
    
    return {
        'source': source,
        'langsmith_enabled': bool(langchain_key)
    }


# ==================== åˆå§‹åŒ– RAG ç³»ç»Ÿ ====================
@st.cache_resource
def initialize_rag_system():
    """åˆå§‹åŒ–åŒå‘é‡åº“ RAG ç³»ç»Ÿï¼ˆåŸºç¡€åº“ç¼“å­˜ï¼‰"""
    rag = DualVectorStoreRAG()
    
    # åˆå§‹åŒ–åŸºç¡€å‘é‡åº“ï¼ˆç¼“å­˜ï¼‰
    with st.spinner("ğŸ“š æ­£åœ¨åˆå§‹åŒ–åŸºç¡€çŸ¥è¯†åº“..."):
        base_doc_count = rag.initialize_base_vectorstore()
    
    # åˆå§‹åŒ–ç”¨æˆ·å‘é‡åº“ï¼ˆä¸ç¼“å­˜ï¼ŒåŠ¨æ€ï¼‰
    rag.initialize_user_vectorstore()
    
    return rag, base_doc_count


# ==================== åˆå§‹åŒ–æ–‡æ¡£ç®¡ç†å™¨ ====================
def get_document_manager():
    """è·å–æ–‡æ¡£ç®¡ç†å™¨å®ä¾‹"""
    if 'doc_manager' not in st.session_state:
        st.session_state.doc_manager = DocumentManager()
    return st.session_state.doc_manager


# ==================== ä¸»åº”ç”¨é€»è¾‘ ====================
def main():
    try:
        # åŠ è½½é…ç½®
        config = load_config()
        
        # åˆå§‹åŒ– RAG ç³»ç»Ÿ
        rag_system, base_doc_count = initialize_rag_system()
        st.success(f"âœŒï¸ System All Set!  {base_doc_count} default docs loaded!")
        
        # åˆå§‹åŒ–æ–‡æ¡£ç®¡ç†å™¨
        doc_manager = get_document_manager()
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        if 'qa_history' not in st.session_state:
            st.session_state.qa_history = []
        if 'show_doc_manager' not in st.session_state:
            st.session_state.show_doc_manager = False
        
        # ==================== æ–‡æ¡£ä¸Šä¼ åŒºåŸŸ ====================
        st.markdown("---")
        st.markdown("### ğŸ›œ Upload Your Documents Here")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            uploaded_files = st.file_uploader(
                "Upload your PDF files to library (batch uploading available)",
                type=['pdf'],
                accept_multiple_files=True,
                help="PDF files only, allowed to select multiple files with a 50 MB size limit for each one.",
                key="pdf_uploader"
            )
        
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)  # å¯¹é½æŒ‰é’®
            if st.button("Manage Uploaded Docs", use_container_width=True):
                st.session_state.show_doc_manager = not st.session_state.show_doc_manager
        
        # ==================== æ‰¹é‡æ–‡ä»¶ä¸Šä¼ å¤„ç† ====================
        if uploaded_files is not None and len(uploaded_files) > 0:
            # å¯¼å…¥æ‰¹é‡ä¸Šä¼ è¾…åŠ©æ¨¡å—
            from batch_upload_helper import (
                generate_batch_id, initialize_batch_state, get_file_key,
                update_file_status, get_pending_files, get_failed_files,
                get_batch_progress, get_batch_summary, should_process_file
            )
            
            # ç”Ÿæˆå½“å‰æ‰¹æ¬¡ID
            current_batch_id = generate_batch_id(uploaded_files)
            
            # åˆå§‹åŒ–æ‰¹æ¬¡çŠ¶æ€ï¼ˆå¦‚æœæ˜¯æ–°æ‰¹æ¬¡ï¼‰
            if 'batch_upload_state' not in st.session_state:
                st.session_state.batch_upload_state = None
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ‰¹æ¬¡
            if (st.session_state.batch_upload_state is None or 
                st.session_state.batch_upload_state['batch_id'] != current_batch_id):
                # æ–°æ‰¹æ¬¡ï¼Œåˆå§‹åŒ–çŠ¶æ€
                st.session_state.batch_upload_state = initialize_batch_state(
                    uploaded_files, current_batch_id
                )
            
            batch_state = st.session_state.batch_upload_state
            
            # æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©ä¿¡æ¯
            if len(uploaded_files) > 1:
                st.info(f"ğŸ“¦ å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            
            # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
            progress = get_batch_progress(batch_state)
            if progress > 0:
                st.progress(progress, text=get_batch_summary(batch_state))
            
            # å¤„ç†å¾…å¤„ç†å’Œå¤±è´¥çš„æ–‡ä»¶
            files_to_process = []
            for file in uploaded_files:
                file_key = get_file_key(file)
                if should_process_file(batch_state, file_key):
                    files_to_process.append((file, file_key))
            
            # å¦‚æœæœ‰æ–‡ä»¶éœ€è¦å¤„ç†
            if files_to_process:
                # é¡ºåºå¤„ç†æ¯ä¸ªæ–‡ä»¶
                for file, file_key in files_to_process:
                    file_info = batch_state['files'][file_key]
                    
                    # æ ‡è®°ä¸ºå¤„ç†ä¸­
                    update_file_status(batch_state, file_key, 'processing')
                    
                    with st.status(f"ğŸ“¥ æ­£åœ¨å¤„ç†: {file_info['filename']}", expanded=True) as status:
                        try:
                            # é˜¶æ®µ1: ä¸Šä¼ å’Œä¿å­˜æ–‡ä»¶
                            st.write("éªŒè¯æ–‡ä»¶æ ¼å¼å’Œå¤§å°...")
                            success, message, metadata = doc_manager.upload_document(file)
                            
                            if not success:
                                # ä¸Šä¼ å¤±è´¥ï¼ˆæ ¼å¼é”™è¯¯ã€é‡å¤æ–‡ä»¶ç­‰ï¼‰
                                status.update(label=f"âŒ {file_info['filename']} ä¸Šä¼ å¤±è´¥", state="error")
                                update_file_status(batch_state, file_key, 'failed', error=message)
                                st.error(f"âŒ {message}")
                                continue  # è·³è¿‡è¿™ä¸ªæ–‡ä»¶ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                            
                            st.write("âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
                            
                            # é˜¶æ®µ2: ç´¢å¼•åˆ°å‘é‡åº“
                            st.write("ğŸ”¢ æ­£åœ¨å‘é‡åŒ–æ–‡æ¡£...")
                            index_success, index_message, chunk_count = rag_system.add_user_document(
                                file_path=metadata['filepath'],
                                original_filename=metadata['original_filename'],
                                upload_time=metadata['upload_time'],
                                file_size=metadata['size']
                            )
                            
                            if not index_success:
                                # ç´¢å¼•å¤±è´¥ï¼Œæ¸…ç†å·²ä¿å­˜çš„æ–‡ä»¶
                                status.update(label=f"âŒ {file_info['filename']} ç´¢å¼•å¤±è´¥", state="error")
                                st.error(index_message)
                                st.warning("æ­£åœ¨æ¸…ç†å·²ä¿å­˜çš„æ–‡ä»¶...")
                                
                                file_success, file_error = safe_remove_file(metadata['filepath'])
                                if file_success:
                                    st.info("âœ… å·²æ¸…ç†å¤±è´¥çš„ä¸Šä¼ ")
                                
                                update_file_status(batch_state, file_key, 'failed', error=index_message)
                                continue  # è·³è¿‡è¿™ä¸ªæ–‡ä»¶ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                            
                            # é˜¶æ®µ3: ä¿å­˜å…ƒæ•°æ®
                            save_success, save_error = doc_manager.save_document_metadata(metadata)
                            
                            if not save_success:
                                # å…ƒæ•°æ®ä¿å­˜å¤±è´¥ï¼ˆæå°‘è§ï¼‰
                                status.update(label=f"âš ï¸ {file_info['filename']} å…ƒæ•°æ®ä¿å­˜å¤±è´¥", state="error")
                                st.error(f"âŒ {save_error}")
                                st.warning("æ–‡æ¡£å·²ç´¢å¼•ä½†å…ƒæ•°æ®æœªä¿å­˜ï¼Œå¯èƒ½å¯¼è‡´é‡å¤ä¸Šä¼ æ£€æµ‹å¤±è´¥")
                                update_file_status(batch_state, file_key, 'failed', error=save_error)
                                continue
                            
                            # å…¨éƒ¨æˆåŠŸ
                            status.update(label=f"âœ… {file_info['filename']} å¤„ç†å®Œæˆ", state="complete")
                            st.success(f"ğŸ‰ {metadata['original_filename']} å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“ï¼")
                            st.info(index_message)
                            
                            update_file_status(batch_state, file_key, 'success')
                            
                        except Exception as e:
                            # æ„å¤–é”™è¯¯
                            status.update(label=f"âŒ {file_info['filename']} å¤„ç†å¼‚å¸¸", state="error")
                            error_msg = f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                            st.error(error_msg)
                            update_file_status(batch_state, file_key, 'failed', error=error_msg)
                    
                    # æ¯å¤„ç†å®Œä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ·æ–°ä¸€æ¬¡é¡µé¢ä»¥æ›´æ–°è¿›åº¦
                    if batch_state['completed_files'] < batch_state['total_files']:
                        st.rerun()
            
            # æ‰¹æ¬¡å¤„ç†å®Œæˆ
            if batch_state['overall_status'] == 'completed':
                st.markdown("---")
                
                # æ˜¾ç¤ºæ‰¹æ¬¡æ‘˜è¦
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("âœ… æˆåŠŸ", batch_state['success_count'])
                with col2:
                    st.metric("âŒ å¤±è´¥", batch_state['failed_count'])
                with col3:
                    st.metric("ğŸ“Š æ€»è®¡", batch_state['total_files'])
                
                # æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶è¯¦æƒ…
                if batch_state['failed_count'] > 0:
                    with st.expander("æŸ¥çœ‹å¤±è´¥æ–‡ä»¶è¯¦æƒ…", expanded=False):
                        for file_key, file_info in batch_state['files'].items():
                            if file_info['status'] == 'failed':
                                st.error(f"**{file_info['filename']}**: {file_info['error']}")
                    
                    # æä¾›é‡è¯•é€‰é¡¹
                    if st.button("ğŸ”„ é‡è¯•å¤±è´¥çš„æ–‡ä»¶"):
                        # å°†å¤±è´¥æ–‡ä»¶é‡ç½®ä¸º pending çŠ¶æ€
                        for file_key in get_failed_files(batch_state):
                            batch_state['files'][file_key]['status'] = 'pending'
                            batch_state['files'][file_key]['error'] = None
                        
                        batch_state['overall_status'] = 'processing'
                        batch_state['failed_count'] = 0
                        batch_state['completed_files'] -= len(get_failed_files(batch_state))
                        st.rerun()
                
                # å®Œæˆåçš„æç¤º
                if batch_state['success_count'] > 0:
                    st.success(f"ğŸŠ æ‰¹é‡ä¸Šä¼ å®Œæˆï¼æˆåŠŸå¤„ç† {batch_state['success_count']} ä¸ªæ–‡ä»¶")
        
        # ==================== æ–‡æ¡£ç®¡ç†æµ®çª— ====================
        if st.session_state.show_doc_manager:
            with st.expander("ğŸ“š å·²ä¸Šä¼ æ–‡æ¡£ç®¡ç†", expanded=True):
                documents = doc_manager.list_documents()
                
                if not documents:
                    st.info("ğŸ“­ è¿˜æ²¡æœ‰ä¸Šä¼ ä»»ä½•æ–‡æ¡£")
                else:
                    st.caption(f"å…± {len(documents)} ä¸ªæ–‡æ¡£")
                    
                    for doc in documents:
                        col1, col2, col3, col4 = st.columns([3, 2, 2, 1])
                        
                        with col1:
                            st.markdown(f"**ğŸ“„ {doc['original_filename']}**")
                        
                        with col2:
                            st.text(f"ğŸ“¦ {doc['size_formatted']}")
                        
                        with col3:
                            st.text(f"ğŸ• {doc['upload_time']}")
                        
                        with col4:
                            if st.button("ğŸ—‘ï¸", key=f"del_{doc['file_id']}", help="Delete"):
                                # åˆ é™¤æ–‡ä»¶
                                file_success, file_message = doc_manager.delete_document(doc['file_id'])
                                
                                # ä»å‘é‡åº“åˆ é™¤
                                vec_success, vec_message = rag_system.remove_user_document(
                                    doc['original_filename']
                                )
                                
                                if file_success:
                                    st.success(file_message)
                                    if vec_success:
                                        st.info(vec_message)
                                    else:
                                        st.warning(vec_message)
                                    st.rerun()
                                else:
                                    st.error(file_message)
                        
                        st.markdown("---")
        
        # ==================== é—®ç­”åŒºåŸŸ ====================
        st.markdown("---")
        st.markdown("### ğŸ™‹ Question")
        
        question = st.text_area(
            f"Please enter your question here: \n (**Note: The system currently answers questions only based on materials in the database, it'll answer *I don't know based on the provided context.* if it failed to find answer from the docs.**)",
            placeholder="Can you list some of the hyperparameters in the FFN?",
            height=100,
            key="question_input"
        )
        
        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            ask_button = st.button("Shoot", type="primary", use_container_width=True)
        with col2:
            if st.button("Clean The History", use_container_width=True):
                st.session_state.qa_history = []
                st.rerun()
        
        if ask_button and question.strip():
            with st.spinner("(ãƒ¼_ãƒ¼ã‚ thinking~~~"):
                try:
                    # åˆ›å»º RAG é“¾å¹¶æŸ¥è¯¢
                    rag_chain = rag_system.create_rag_chain(k=3)
                    response = rag_chain.invoke(question)
                    
                    # ä¿å­˜åˆ°å†å²è®°å½•
                    qa_entry = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'question': question.strip(),
                        'answer': response.content
                    }
                    st.session_state.qa_history.append(qa_entry)
                    
                    # æ˜¾ç¤ºå½“å‰å›ç­”
                    st.markdown("### Answer")
                    st.info(response.content)
                    
                except Exception as e:
                    st.error(f"ğŸ˜­ Get an error: {str(e)}")
        
        elif ask_button:
            st.warning("ğŸ¤” Got nothing to ask yet?")
        
        # ==================== é—®ç­”å†å²è®°å½• ====================
        if st.session_state.qa_history:
            st.markdown("---")
            st.markdown("## QA History")
            st.caption(f"You got {len(st.session_state.qa_history)} histories in total.")
            
            # é€†åºæ˜¾ç¤ºï¼ˆæœ€æ–°çš„åœ¨ä¸Šé¢ï¼‰
            for idx, qa in enumerate(reversed(st.session_state.qa_history), 1):
                with st.expander(
                    f"ğŸ• {qa['timestamp']} - Question #{len(st.session_state.qa_history) - idx + 1}",
                    expanded=(idx == 1)
                ):
                    st.markdown(f"**Question:**")
                    st.write(qa['question'])
                    st.markdown(f"**Answer:**")
                    st.info(qa['answer'])
        
        # ==================== ä¾§è¾¹æ  ====================
        with st.sidebar:
            st.header("About")
            st.markdown("""
            This is a academic QA system on the strength of RAG.
            
            **Highlights:**
            - Supports users to upload custom docs.
            - Load, analyze and process pdf type of docs.
            - Performs semantic retrieval to identify the most relevant content chunks.
            - Generates accurate answers using OpenAI GPT-3.5 within a RAG pipeline.
            - Implements a LangChain-based Retrieval-Augmented Generation workflow.
            - Restricts responses only based on course materials to minimize hallucinations.
            - Automatically stores QA history for session continuity.
            - Clearly distinguishes content sources (default vs. user-uploaded).
            
            **Guide:**
            1. Upload your PDF docs (if you'd like to ask questions related to them).
            2. Enter your question in the input field.
            3. Click the â€œShootâ€ button.
            4. Wait for the answer.
            5. Previous questions and answers will be automatically saved below.
            6. Click â€œManage Uploaded Docsâ€ to view or remove uploaded files.

            **Sample Questions: **
            - Can you list some of the hyperparameters in the FFN?
            - What is backpropagation?
            - Explain gradient descent
            """)
            
            st.divider()
            
            st.header("ğŸ§‘â€ğŸ’» Tech Stack:")
            st.markdown("""
            - **Front End**: Streamlit by Codegen
            - **LLM**: OpenAI GPT-3.5
            - **Vector Database**: Chroma (Locally Persistence)
            - **Framework**: LangChain
            - **Docs Processing**: PyPDF
            - **Architecture**: Double Vector Database (Default + User)
            """)
            
            st.divider()
            
            # å­˜å‚¨ä½¿ç”¨æƒ…å†µ
            try:
                upload_dir = "UserUploads"
                if os.path.exists(upload_dir):
                    total_size = get_directory_size(upload_dir)
                    st.metric(
                        label="ğŸ“Š Data Uploaded",
                        value=format_file_size(total_size)
                    )
            except:
                pass
            
            st.markdown("---")
            st.caption("ğŸ”” Note: Initial document loading and vectorization may take a few moments on first use.")
    
    except Exception as e:
        st.error(f"âŒ ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}")
        st.info("""
        è¯·æ£€æŸ¥ï¼š
        - OpenAI API Key æ˜¯å¦æ­£ç¡®
        - CourseMaterials/deep_learning ç›®å½•ä¸‹æ˜¯å¦æœ‰PDFæ–‡ä»¶
        - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
        """)


if __name__ == "__main__":
    main()
